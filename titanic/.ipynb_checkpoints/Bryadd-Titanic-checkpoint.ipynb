{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy as sp\n",
    "import sklearn \n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Model Algoriths\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier # conda install -c conda-forge xgboost\n",
    "\n",
    "#Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Ignore the shitload of conversion warnings we get. \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "\n",
    "# Files live in the same folder as this notebook. \n",
    "submission_example = pd.read_csv('gender_submission.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Making a copy to play with. \n",
    "data1 = train.copy(deep = True)\n",
    "\n",
    "# Making a list of both trains so we can clean them at once later.\n",
    "data_cleaner = [data1, train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're familiar with the data we need to first clean it.\n",
    "\n",
    "The 4 C's:\n",
    "Correcting - remove broken data. Like if age is 800 somewhere or something. Doesn't look like it.\n",
    "\n",
    "Completing - filling null values. Many algorithms don't know how to deal so we need to fix. We need to impute missing values especially for age. We might need to change this process if we realize that filling it with the mean or something isn't working well. What I'm reading suggests we should use the median for age, drop the 'cabin' column and use mode to impute 'embark'. \n",
    "\n",
    "Create - Feature engineering\n",
    "\n",
    "Converting - changing over dates or data types that don't work well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()\n",
    "# train.describe()\n",
    "# train.sample(10)\n",
    "\n",
    "# going to work on having prettier print functions in this notebook.\n",
    "\n",
    "# print('Train columns with null values:\\n', data1.isnull().sum())\n",
    "# print(\"-\"*10)\n",
    "\n",
    "# print('Test columns with nulls:\\n', test.isnull().sum())\n",
    "# print(\"-\"*10)\n",
    "\n",
    "# looks like the ratio of missing age and cabin are the same across the train and test sets.\n",
    "# proof the sample is actually random between the two. \n",
    "# We need to fix these two columns along with Embarked if we can hope to model correctly.\n",
    "# in the future I would make several different versions of these dataframes,\n",
    "# testing different imputation methods to see which one works the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filling the data\n",
    "\n",
    "for dataset in data_cleaner: # do em both at once\n",
    "    # Fill missing age\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True) # this doesn't work well without inplace\n",
    "    \n",
    "    # fill embarked\n",
    "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
    "    \n",
    "    # fill missing fare with median\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n",
    "    \n",
    "    # we need to drop Passenger ID and ticket because they're just random identifiers with no purpose\n",
    "    # we also want to drop Cabin because it has too many Nulls\n",
    "\n",
    "drop_column = ['PassengerId', 'Cabin', 'Ticket'] # make a list it's easier\n",
    "data1.drop(drop_column, axis=1, inplace = True) # axis means column, inplace makes it persistent without needing to make a new variable\n",
    "\n",
    "\n",
    "\n",
    "# Time to create some features for both datasets. \n",
    "\n",
    "for dataset in data_cleaner:\n",
    "    # How about creating family size per person? \n",
    "    # makes sense that families would work together to survive\n",
    "    # and families prioritized in lifeboats\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1 # plus one to account for the person themselves\n",
    "    \n",
    "    dataset['IsAlone'] = 1\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n",
    "    # if you are alone, it's a 1, if not, it's a zero\n",
    "    # this is a binary column\n",
    "    \n",
    "    # The names have titles with them, \"Mr\" \"Miss\" \"Master\" so let's cut those off and turn them into a feature!\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    # We should also place the fares into bins. I don't really know how this works but I'm going to try qcut\n",
    "    # Ref: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    # Ref: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "    \n",
    "    # Using regular cut to bin the ages:\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n",
    "    \n",
    "    \n",
    "\n",
    "# So here's where I'm getting some guidance from other notebooks. We need to clean up rare title names.\n",
    "# print(data1['Title'].value_counts())\n",
    "# Like, lmaowtf: https://en.wikipedia.org/wiki/Jonkheer\n",
    "\n",
    "stat_min = 10 \n",
    "# Using ten as the minimum because this article says so: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (data1['Title'].value_counts() < stat_min) # creates a true/false series with title name as the index\n",
    "\n",
    "# What we're going to do is replace the random ones below ten. \n",
    "# lambda functions \n",
    "\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(data1['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert categorical data to dummy variables for mathematical analysis. We're going to encode using the inherent sklearn and pandas tools, nothing fancy. \n",
    "\n",
    "I know that SciKit has a new library called ColumnTransformer that has replaced LabelEncoding but I haven't learned how to use it yet. \n",
    "\n",
    "https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n",
    "\n",
    "Let's try to use this next time:\n",
    "https://towardsdatascience.com/columntransformer-in-scikit-for-labelencoding-and-onehotencoding-in-machine-learning-c6255952731b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_cleaner:\n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n",
    "\n",
    "# We now can define a y variable, the target outcome:\n",
    "Target = ['Survived']\n",
    "\n",
    "# Defining the X variables for feature selection\n",
    "data1_x = ['Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] # pretty names for charts\n",
    "data1_x_calc = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare'] # These are the actual coded columns we're gonna use\n",
    "\n",
    "data1_xy = Target + data1_x # combining them \n",
    "\n",
    "# Define the x variables for the origiunal data with bin features to remove any continuous variables\n",
    "data1_x_bin = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data_xy_bin = Target + data1_x_bin  # so what we've done is made two versions of the test data, one continuous and one binned\n",
    "\n",
    "# We need to turn the categorical variables into dummy variables, putting them in their own columns with binary 1/0 data inside them.\n",
    "data1_dummy = pd.get_dummies(data1[data1_x]) # ran this on that list of column names from above\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy # add the target variable, naturally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch   Age     Fare  FamilySize  IsAlone  Sex_female  \\\n",
       "0       3      1      0  22.0   7.2500           2        0           0   \n",
       "1       1      1      0  38.0  71.2833           2        0           1   \n",
       "2       3      0      0  26.0   7.9250           1        1           1   \n",
       "3       1      1      0  35.0  53.1000           2        0           1   \n",
       "4       3      0      0  35.0   8.0500           1        1           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  \\\n",
       "0         1           0           0           1             0           0   \n",
       "1         0           1           0           0             0           0   \n",
       "2         0           0           0           1             0           0   \n",
       "3         0           0           0           1             0           0   \n",
       "4         1           0           0           1             0           0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  \n",
       "0           0         1          0  \n",
       "1           0         0          1  \n",
       "2           1         0          0  \n",
       "3           0         0          1  \n",
       "4           0         1          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've put together all our data, we need to split some test and train data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split using randomstate\n",
    "train1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0) # using the preset variables from above to keep this function clean. \n",
    "train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target], random_state = 0) # doing the same, but with bins\n",
    "\n",
    "train1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is clean, we're going to explore the data and see if we can find some basic correlations to inform what we do next. I have some ideas, but for the sake of science let's examine everything equally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Correlation by: Sex\n",
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n",
      "Survival Correlation by: Pclass\n",
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n",
      "Survival Correlation by: Embarked\n",
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n",
      "Survival Correlation by: Title\n",
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Misc  0.444444\n",
      "2    Miss  0.697802\n",
      "3      Mr  0.156673\n",
      "4     Mrs  0.792000\n",
      "Survival Correlation by: SibSp\n",
      "   SibSp  Survived\n",
      "0      0  0.345395\n",
      "1      1  0.535885\n",
      "2      2  0.464286\n",
      "3      3  0.250000\n",
      "4      4  0.166667\n",
      "5      5  0.000000\n",
      "6      8  0.000000\n",
      "Survival Correlation by: Parch\n",
      "   Parch  Survived\n",
      "0      0  0.343658\n",
      "1      1  0.550847\n",
      "2      2  0.500000\n",
      "3      3  0.600000\n",
      "4      4  0.000000\n",
      "5      5  0.200000\n",
      "6      6  0.000000\n",
      "Survival Correlation by: FamilySize\n",
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n",
      "Survival Correlation by: IsAlone\n",
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n",
      "Survived    0    1\n",
      "Title             \n",
      "Master     17   23\n",
      "Misc       15   12\n",
      "Miss       55  127\n",
      "Mr        436   81\n",
      "Mrs        26   99\n"
     ]
    }
   ],
   "source": [
    "for x in data1_x:\n",
    "     if data1[x].dtype != 'float64' : \n",
    "            print('Survival Correlation by:', x)\n",
    "            print(data1[[x, Target[0]]].groupby(x, as_index=False).mean())\n",
    "\n",
    "print(pd.crosstab(data1['Title'], data1[Target[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping visualization because we need faster, better ways to do it. Next step, modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"No Free Lunch Theorem\" = there is no super algorithm that works best. The best approach is to try several and pick the one that works best for your situation.\n",
    "# to that end, we're going to set up a bunch and try them.\n",
    "\n",
    "# I love this format because this is some copy/paste code we can run again to quickly run the data through every single algorithm, score them and easily visualize. \n",
    "# Should we turn this into a function eventually? I'm game for it \n",
    "\n",
    "MLA = [\n",
    "    # Ensemble\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    \n",
    "    # Gaussian Process\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    # GLM\n",
    "    linear_model.LogisticRegression(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifier(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    # Naive Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    # Nearest Neighbors\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    # SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    # Trees\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    # Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "    #xgboost MONEY GANG\n",
    "    XGBClassifier()\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to try splitting in cross-validation with this splitter class, which is an alternative to train_test_split\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0) # this intentionally leaves out 10% of the model - I am not sure why this is a good idea but I hear it is\n",
    "\n",
    "# We are going to create a table to compare all the MLAs and see what their score is\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "# Create table to compare MLA predictions\n",
    "MLA_predict = data1[Target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index through the MLA and save the performance to put it in a table - this is the money moment. \n",
    "# Really should wrap this in a function for ease of use later. Does one of those exist already, maybe?\n",
    "\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    \n",
    "    # set the name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    # We are going to score the model with cross validation.\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    \n",
    "    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv = cv_split, return_train_score=True) # The code has changed since the guide went live. You now have to tell it to return the train score. \n",
    "    \n",
    "    # simply reference the cv_results output column by column and format it the way we want. \n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean() # How long does it take? We're speed racers out here\n",
    "\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
    "    \n",
    "    # If this is a non-bias random sample, then +/- 3 standard deviations from the mean should statistically capture 99.7% of the subsets. \n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3 # This will tell us the worst that can happen\n",
    "    \n",
    "    # save them for export\n",
    "    alg.fit(data1[data1_x_bin], data1[Target])\n",
    "    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "    \n",
    "    row_index+=1 # add one to the row index so it moves to the next row.\n",
    "    \n",
    "    \n",
    "# print and sort the table. \n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending=False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perry aye "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy Mean</th>\n",
       "      <th>MLA Test Accuracy 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
       "      <td>0.856367</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.0527546</td>\n",
       "      <td>0.0443746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "      <td>0.890824</td>\n",
       "      <td>0.827985</td>\n",
       "      <td>0.0526119</td>\n",
       "      <td>0.0111429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'class_weight': ...</td>\n",
       "      <td>0.837266</td>\n",
       "      <td>0.826119</td>\n",
       "      <td>0.0453876</td>\n",
       "      <td>0.0302742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.822761</td>\n",
       "      <td>0.0498731</td>\n",
       "      <td>0.0623156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.822761</td>\n",
       "      <td>0.0520853</td>\n",
       "      <td>0.00369406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MLA Name  \\\n",
       "21               XGBClassifier   \n",
       "4       RandomForestClassifier   \n",
       "14                         SVC   \n",
       "3   GradientBoostingClassifier   \n",
       "17      DecisionTreeClassifier   \n",
       "\n",
       "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
       "21  {'base_score': 0.5, 'booster': 'gbtree', 'cols...                0.856367   \n",
       "4   {'bootstrap': True, 'class_weight': None, 'cri...                0.890824   \n",
       "14  {'C': 1.0, 'cache_size': 200, 'class_weight': ...                0.837266   \n",
       "3   {'criterion': 'friedman_mse', 'init': None, 'l...                0.866667   \n",
       "17  {'class_weight': None, 'criterion': 'gini', 'm...                0.895131   \n",
       "\n",
       "   MLA Test Accuracy Mean MLA Test Accuracy 3*STD    MLA Time  \n",
       "21               0.829478               0.0527546   0.0443746  \n",
       "4                0.827985               0.0526119   0.0111429  \n",
       "14               0.826119               0.0453876   0.0302742  \n",
       "3                0.822761               0.0498731   0.0623156  \n",
       "17               0.822761               0.0520853  0.00369406  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
